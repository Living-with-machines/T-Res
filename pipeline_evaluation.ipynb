{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f90208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "from utils import ner, linking, evaluate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ae14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to NER Model:\n",
    "ner_model = \"./outputs/models/lwm-ner.model\"\n",
    "\n",
    "# Load NER pipeline, aggregate grouped entities with \"average\":\n",
    "ner_pipe = pipeline(\"ner\", model=ner_model, aggregation_strategy=\"average\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to DeezyMatch model and combined candidate vectors:\n",
    "dm_path = \"./outputs/deezymatch/\"\n",
    "dm_cands = \"wkdtalts\"\n",
    "dm_model = \"ocr_faiss_cur085_l2\"\n",
    "dm_output = \"deezymatch_on_the_fly\"\n",
    "\n",
    "# Load mentions to wikidata dictionary\n",
    "with open('/resources/wikidata/mentions_to_wikidata_normalized.json', 'r') as f:\n",
    "    mentions_to_wikidata_normalized = json.load(f)\n",
    "    \n",
    "# Load wikipedia frequency dictionary by wikidata ID\n",
    "with open('/resources/wikidata/overall_entity_freq_wikidata.json', 'r') as f:\n",
    "    overall_entity_freq_wikidata = json.load(f)\n",
    "    \n",
    "# Load wikidata gazetteer\n",
    "gazdf = pd.read_csv(\"/resources/wikidata/wikidata_gazetteer.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ab390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "df = pd.read_csv(\"outputs/data/linking_lwm_df_test.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Split test set into dev and test set:\n",
    "# We will use dev for evaluation for now, we keep test unseen until the very last experiments:\n",
    "dev, test = train_test_split(df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "publicationToWikidata = {\"Dorchester\": \"Q503331\",\n",
    "                         \"Ashton-under-Lyne\": \"Q659803\",\n",
    "                         \"Manchester\": \"Q18125\",\n",
    "                         \"Poole\": \"Q203349\"}\n",
    "\n",
    "dev[\"place_publ_wk\"] = dev['place'].map(publicationToWikidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84307f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev = dev.iloc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_toponyms_precision(found, given):\n",
    "    \n",
    "    # Reformat dictionaries to make them easy to compare\n",
    "    dFound = dict()\n",
    "    for tf in found:\n",
    "        dFound[(tf[\"start\"], tf[\"end\"])] = (tf[\"toponym\"], tf[\"place_class\"])\n",
    "    dGiven = dict()\n",
    "    for gt in given:\n",
    "        dGiven[(gt[\"start\"], gt[\"end\"])] = (gt[\"toponym\"], gt[\"place_class\"])\n",
    "    \n",
    "    # Check for precision:\n",
    "    true_pos_identified = 0\n",
    "    true_pos_classified = 0\n",
    "    false_pos_identified = 0\n",
    "    false_pos_classified = 0\n",
    "    \n",
    "    for tf in dFound:\n",
    "        if tf in dGiven:\n",
    "            true_pos_identified += 1\n",
    "            if dFound[tf][1] == dGiven[tf][1]:\n",
    "                true_pos_classified += 1\n",
    "            else:\n",
    "                false_pos_classified += 1\n",
    "        else:\n",
    "            false_pos_identified += 1\n",
    "    \n",
    "    return true_pos_identified, true_pos_classified, false_pos_identified, false_pos_classified\n",
    "\n",
    "def compare_toponyms_recall(found, given):\n",
    "    \n",
    "    # Reformat dictionaries to make them easy to compare\n",
    "    dFound = dict()\n",
    "    for tf in found:\n",
    "        dFound[(tf[\"start\"], tf[\"end\"])] = (tf[\"toponym\"], tf[\"place_class\"])\n",
    "    dGiven = dict()\n",
    "    for gt in given:\n",
    "        dGiven[(gt[\"start\"], gt[\"end\"])] = (gt[\"toponym\"], gt[\"place_class\"])\n",
    "    \n",
    "    # Check for recall:\n",
    "    true_pos_identified = 0\n",
    "    true_pos_classified = 0\n",
    "    false_neg_identified = 0\n",
    "    false_neg_classified = 0\n",
    "    \n",
    "    for tf in dGiven:\n",
    "        if tf in dFound:\n",
    "            true_pos_identified += 1\n",
    "            if dFound[tf][1] == dGiven[tf][1]:\n",
    "                true_pos_classified += 1\n",
    "            else:\n",
    "                false_neg_classified += 1\n",
    "        else:\n",
    "            false_neg_identified += 1\n",
    "    \n",
    "    return true_pos_identified, true_pos_classified, false_neg_identified, false_neg_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fef21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dSentences = dict()\n",
    "dAnnotations = dict()\n",
    "dPublication = dict()\n",
    "\n",
    "dev_sents = dev.drop_duplicates(subset=[\"article_id\", \"sent_id\", \"current_sentence\"])\n",
    "for i, row in dev_sents.iterrows():\n",
    "    artid = row[\"article_id\"]\n",
    "    sentid = row[\"sent_id\"]\n",
    "    fullid = str(artid) + \"_\" + str(sentid)\n",
    "    dSentences[fullid] = row[\"current_sentence\"]\n",
    "    dPublication[fullid] = row[\"place_publ_wk\"]\n",
    "    tmpdf = dev[(dev[\"article_id\"] == artid) & (dev[\"sent_id\"] == sentid)]\n",
    "    for i2, row2 in tmpdf.iterrows():\n",
    "        t_position = (row2[\"start\"], row2[\"end\"])\n",
    "        if fullid in dAnnotations:\n",
    "            dAnnotations[fullid].append({\"start\": row2[\"start\"],\n",
    "                                         \"end\": row2[\"end\"],\n",
    "                                         \"toponym\": row2[\"mention\"],\n",
    "                                         \"place_class\": row2[\"place_class\"],\n",
    "                                         \"link\": row2[\"place_wqid\"]})\n",
    "        else:\n",
    "            dAnnotations[fullid] = [{\"start\": row2[\"start\"],\n",
    "                                     \"end\": row2[\"end\"],\n",
    "                                     \"toponym\": row2[\"mention\"],\n",
    "                                     \"place_class\": row2[\"place_class\"],\n",
    "                                     \"link\": row2[\"place_wqid\"]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "dResolved = dict()\n",
    "precision = []\n",
    "recall = []\n",
    "for sentid in dAnnotations:\n",
    "    found_toponyms = ner.find_grouped_entities(dSentences[sentid], ner_pipe)\n",
    "    precision.append(compare_toponyms_precision(found_toponyms, dAnnotations[sentid]))\n",
    "    recall.append(compare_toponyms_recall(found_toponyms, dAnnotations[sentid]))\n",
    "    # Use DeezyMatch to find the most similar place name in our gazetteer:\n",
    "    candidate_mentions = linking.deezy_on_the_fly(found_toponyms, dm_cands, dm_model,\n",
    "                                              dm_output, dm_path, thr=10, cands=3,\n",
    "                                              cdiff=2)\n",
    "    resolved_entities = linking.resolve_baseline1(candidate_mentions,\n",
    "                                              mentions_to_wikidata_normalized,\n",
    "                                              overall_entity_freq_wikidata,\n",
    "                                              gazdf, dPublication[sentid],\n",
    "                                              max_relv=1000, max_dist=200,\n",
    "                                              dmthr=10, max_mentions=3)\n",
    "    \n",
    "    dResolved[sentid] = resolved_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d510df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Time NER for 435 sentences\n",
    "# import time\n",
    "# print(len(dAnnotations))\n",
    "# start_time = time.time()\n",
    "# for sentid in dAnnotations:\n",
    "#     found_toponyms = ner.find_grouped_entities(dSentences[sentid], ner_pipe)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_linking(found, given):\n",
    "    corr = 0\n",
    "    incorr = 0\n",
    "    # Reformat dictionaries to make them easy to compare\n",
    "    dFound = dict()\n",
    "    for tf in found:\n",
    "        if found[tf]:\n",
    "            dFound[tf] = found[tf][0]\n",
    "    dGiven = dict()\n",
    "    for gt in given:\n",
    "        if gt[\"place_class\"] == \"LOC\":\n",
    "            dGiven[gt[\"toponym\"]] = gt[\"link\"]\n",
    "    for t in dFound:\n",
    "        if t in dGiven:\n",
    "            if dFound[t] == dGiven[t]:\n",
    "                corr += 1\n",
    "            else:\n",
    "                incorr += 1\n",
    "    return corr, incorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "for sentid in dAnnotations:\n",
    "    reslink = compare_linking(dResolved[sentid], dAnnotations[sentid])\n",
    "    correct += reslink[0]\n",
    "    incorrect += reslink[1]\n",
    "\n",
    "print(correct/(correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_true_pos_identified = sum([x[0] for x in recall])\n",
    "recall_true_pos_classified = sum([x[1] for x in recall])\n",
    "recall_false_neg_identified = sum([x[2] for x in recall])\n",
    "recall_false_neg_classified = sum([x[3] for x in recall])\n",
    "\n",
    "precision_true_pos_identified = sum([x[0] for x in precision])\n",
    "precision_true_pos_classified = sum([x[1] for x in precision])\n",
    "precision_false_pos_identified = sum([x[2] for x in precision])\n",
    "precision_false_pos_classified = sum([x[3] for x in precision])\n",
    "\n",
    "precision_identified = precision_true_pos_identified / (precision_true_pos_identified + precision_false_pos_identified)\n",
    "precision_classified = precision_true_pos_classified / (precision_true_pos_classified + precision_false_pos_classified)\n",
    "recall_identified = recall_true_pos_identified / (recall_true_pos_identified + recall_false_neg_identified)\n",
    "recall_classified = recall_true_pos_classified / (recall_true_pos_classified + recall_false_neg_classified)\n",
    "\n",
    "print(\"Precision identified:\", precision_identified)\n",
    "# print(precision_classified)\n",
    "print(\"Recall identified:\", recall_identified)\n",
    "# print(recall_classified)\n",
    "\n",
    "fscore_identified = (2 * precision_identified * recall_identified) / (precision_identified + recall_identified)\n",
    "fscore_classified = (2 * precision_classified * recall_classified) / (precision_classified + recall_classified)\n",
    "\n",
    "print(\"F-score identified:\", fscore_identified)\n",
    "print(\"Accuracy classified:\", fscore_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af3c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topoetry",
   "language": "python",
   "name": "topoetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
