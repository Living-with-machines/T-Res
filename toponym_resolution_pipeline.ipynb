{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839bf44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17785b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ner\n",
    "from utils import linking\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import operator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3045a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to NER Model:\n",
    "ner_model = \"./outputs/models/lwm-ner.model\"\n",
    "\n",
    "# Load NER pipeline, aggregate grouped entities with \"average\":\n",
    "ner_pipe = pipeline(\"ner\", model=ner_model, aggregation_strategy=\"average\", use_fast=True)\n",
    "\n",
    "# Path to DeezyMatch model and combined candidate vectors:\n",
    "dm_path = \"./outputs/deezymatch/\"\n",
    "dm_cands = \"wkdtalts\"\n",
    "dm_model = \"ocr_faiss_cur085_l2\"\n",
    "dm_output = \"deezymatch_on_the_fly\"\n",
    "\n",
    "# Load mentions to wikidata dictionary\n",
    "with open('/resources/wikidata/mentions_to_wikidata_normalized.json', 'r') as f:\n",
    "    mentions_to_wikidata_normalized = json.load(f)\n",
    "    \n",
    "# Load wikipedia frequency dictionary by wikidata ID\n",
    "with open('/resources/wikidata/overall_entity_freq_wikidata.json', 'r') as f:\n",
    "    overall_entity_freq_wikidata = json.load(f)\n",
    "    \n",
    "# Load wikidata gazetteer\n",
    "gazdf = pd.read_csv(\"/resources/wikidata/wikidata_gazetteer.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e4e3b",
   "metadata": {},
   "source": [
    "### Input the newspaper text and the Wikidata ID of the place of publication of the newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e63cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newspaper text in which we want to find and geolocate toponyms:\n",
    "text = \"\"\"\n",
    "Mr. Oldham, ol Cheadlc, in Stafford (hire, to Mils Oldlcaa , Lie of this Town.\n",
    "\"\"\"\n",
    "\n",
    "# Wikidata ID of the place where the newspaper is published, e.g. Manchester is Q18125:\n",
    "place_of_publication = \"Q18125\" # Manchester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f66b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mr. Oldham, ol Cheadlc, in Stafford (hire, to Mils Oldlcaa , Lie of this Town.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1deec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wikidata.org/wiki/Q18125\n"
     ]
    }
   ],
   "source": [
    "print(\"https://www.wikidata.org/wiki/\" + place_of_publication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20907d8",
   "metadata": {},
   "source": [
    "### Find toponyms in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ffb801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a sentence and a named entity recogniser, find toponyms in text:\n",
    "found_toponyms = ner.find_grouped_entities(text, ner_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23b7a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found toponyms: 2\n",
      "{'score': 0.994, 'toponym': 'Cheadlc', 'place_class': 'LOC'}\n",
      "{'score': 0.9, 'toponym': 'Stafford (hire', 'place_class': 'LOC'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Found toponyms:\", len(found_toponyms))\n",
    "# Print found toponyms\n",
    "for e in found_toponyms:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2215108",
   "metadata": {},
   "source": [
    "### Perform fuzzy string matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6970ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Use DeezyMatch to find the most similar place name in our gazetteer:\n",
    "candidate_mentions = linking.deezy_on_the_fly(found_toponyms, dm_cands, dm_model,\n",
    "                                              dm_output, dm_path, thr=10, cands=10,\n",
    "                                              cdiff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5607fc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cheadlc': OrderedDict([('Cheadle', 1.3701),\n",
       "              ('Chee Dale', 3.9895),\n",
       "              ('Wheald', 4.0008),\n",
       "              ('Chedan', 4.0618),\n",
       "              ('Chelad', 4.3829),\n",
       "              ('Chade', 4.4776),\n",
       "              ('Charleval', 4.4888),\n",
       "              ('Beechdale', 4.7057)]),\n",
       " 'Stafford (hire': OrderedDict([('Staffordshire', 1.1361),\n",
       "              ('Stafford, Ohio', 4.2757),\n",
       "              ('Salfordshire', 4.7408)])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e6253",
   "metadata": {},
   "source": [
    "### Resolve location names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec5ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_entities = linking.resolve_baseline1(candidate_mentions,\n",
    "                                              mentions_to_wikidata_normalized,\n",
    "                                              overall_entity_freq_wikidata,\n",
    "                                              gazdf, place_of_publication,\n",
    "                                              max_relv=1000, max_dist=200,\n",
    "                                              dmthr=10, max_mentions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25386bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toponym: Cheadlc\n",
      "Wikidata: https://www.wikidata.org/wiki/Q1615894\n",
      "Place name: Cheadle\n",
      "Latitude: 53.3933\n",
      "Longitude: -2.2113\n",
      "Confidence score: 0.69\n",
      "\n",
      "Toponym: Stafford (hire\n",
      "Wikidata: https://www.wikidata.org/wiki/Q23105\n",
      "Place name: Staffordshire\n",
      "Latitude: 52.833333\n",
      "Longitude: -2.0\n",
      "Confidence score: 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in resolved_entities:\n",
    "    print(\"Toponym:\", e)\n",
    "    print(\"Wikidata:\", \"https://www.wikidata.org/wiki/\" + resolved_entities[e][0])\n",
    "    print(\"Place name:\", resolved_entities[e][1])\n",
    "    print(\"Latitude:\", resolved_entities[e][2])\n",
    "    print(\"Longitude:\", resolved_entities[e][3])\n",
    "    print(\"Confidence score:\", round(resolved_entities[e][4], 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b5657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
