{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and using a NER model\n",
    "\n",
    "This notebook shows how to train a new toponym recognition (NER) model, via the `transformers` library.\n",
    "\n",
    "We start by importing some libraries, and the `recogniser` script from the `geoparser` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from t_res.geoparser import recogniser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `myner` object of the `Recogniser` class.\n",
    "\n",
    "> **Note:** The train and test sets for training the NER modules are two json files, one for training and one for testing, in which each item/line in the json corresponds to a sentence. Each sentence-dictionary has three key-value pairs (see two examples below): `id` is an ID of the sentence (a string), `tokens` is the list of tokens into which the sentence has been split, and `ner_tags` is the list of annotations per token (in BIO format). The length of `tokens` and `ner_tags` should always be the same.\n",
    "> ```json\n",
    "> {\"id\":\"3896239_29\",\"ner_tags\":[\"O\",\"B-STREET\",\"I-STREET\",\"O\",\"O\",\"O\",\"B-BUILDING\",\"I-BUILDING\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\"],\"tokens\":[\",\",\"Old\",\"Millgate\",\",\",\"to\",\"the\",\"Collegiate\",\"Church\",\",\",\"where\",\"they\",\"arrived\",\"a\",\"little\",\"after\",\"ten\",\"oclock\",\".\"]}\n",
    "> {\"id\":\"8262498_11\",\"ner_tags\":[\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"B-LOC\",\"O\",\"B-LOC\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\"],\"tokens\":[\"On\",\"the\",\"\\u2018\",\"JSth\",\"November\",\"the\",\"ship\",\"Santo\",\"Christo\",\",\",\"from\",\"Monteveido\",\"to\",\"Cadiz\",\",\",\"with\",\"hides\",\"and\",\"copper\",\".\"]}\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myner = recogniser.Recogniser(\n",
    "    model=\"blb_lwm-ner-fine\",\n",
    "    train_dataset=\"../experiments/outputs/data/lwm/ner_fine_train.json\",  # Path to the json file containing the training set (see note above).\n",
    "    test_dataset=\"../experiments/outputs/data/lwm/ner_fine_dev.json\",  # Path to the json file containing the test set (see note above).\n",
    "    pipe=None,  # We'll store the NER pipeline here, leave this empty.\n",
    "    base_model=\"Livingwithmachines/bert_1760_1900\",  # Base model to fine-tune for NER. The value can be: either \n",
    "                                            # your local path to a model or the huggingface path.\n",
    "                                            # In this case, we use the huggingface path:\n",
    "                                            # https://huggingface.co/Livingwithmachines/bert_1760_1900). You can\n",
    "                                            # chose any other model from the HuggingFace hub, as long as it's\n",
    "                                            # trained on the \"Fill-Mask\" objective (filter by task).\n",
    "    model_path=\"../resources/models/\",  # Path where the NER model will be stored.\n",
    "    training_args={\n",
    "        \"batch_size\": 8,\n",
    "        \"num_train_epochs\": 10,\n",
    "        \"learning_rate\": 0.00005,\n",
    "        \"weight_decay\": 0.0,\n",
    "    }, # Training arguments: you can change them.\n",
    "    overwrite_training=False,  # Set to True if you want to overwrite an existing model with the same name.\n",
    "    do_test=True,  # Set to True if you want to perform the training on test mode (the string \"_test\" will be appended to your model name).\n",
    "    load_from_hub=False, # Whether the final model should be loaded from the HuggingFace hub\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the Recogniser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myner.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to use the model you have just trained, you'll need to load a NER pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myner.pipe = myner.create_pipeline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, use the newly trained model to predict the named entities in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"A remarkable case of rattening has just occurred in the building trade at Sheffield.\"\n",
    "\n",
    "predictions = myner.ner_predict(sentence)\n",
    "print([pred for pred in predictions if pred[\"entity\"] != \"O\"]) # Note that, if you've trained the model in the test mode, the model will probably not identify \"Sheffield\" as a location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resolution-cNmUJBkC-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
