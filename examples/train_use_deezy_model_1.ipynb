{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and using a DeezyMatch model (option 1)\n",
    "\n",
    "This notebook shows how to generate a string pairs dataset and use it to train a new DeezyMatch model.\n",
    "\n",
    "To do so, the `resources/` folder should (at least) contain the following files, in the following locations:\n",
    "```\n",
    "toponym-resolution/\n",
    "   ├── ...\n",
    "   ├── resources/\n",
    "   │   ├── deezymatch/\n",
    "   │   │   ├── data/\n",
    "   │   │   └── inputs/\n",
    "   │   │       ├── characters_v001.vocab\n",
    "   │   │       └── input_dfm.yaml\n",
    "   │   ├── models/\n",
    "   │   │   └── w2v\n",
    "   │   │       ├── w2v_[XXX]_news\n",
    "   │   │       │   ├── w2v.model\n",
    "   │   │       │   ├── w2v.model.syn1neg.npy\n",
    "   │   │       │   └── w2v.model.wv.vectors.npy\n",
    "   │   │       └── ...\n",
    "   │   ├── news_datasets/\n",
    "   │   ├── wikidata/\n",
    "   │   │   └── mentions_to_wikidata.json\n",
    "   │   └── wikipedia/\n",
    "   └── ...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing some libraries, and the `ranking` script from the `geoparser` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.pardir))\n",
    "from geoparser import ranking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `myranker` object of the `Ranker` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myranker = ranking.Ranker(\n",
    "    method=\"deezymatch\", # Here we're telling the ranker to use DeezyMatch.\n",
    "    resources_path=\"../resources/wikidata/\", # Here, the path to the Wikidata resources.\n",
    "    # Parameters to create the string pair dataset:\n",
    "    strvar_parameters={\n",
    "        \"ocr_threshold\": 60,\n",
    "        \"top_threshold\": 85,\n",
    "        \"min_len\": 5,\n",
    "        \"max_len\": 15,\n",
    "        \"w2v_ocr_path\": str(Path(\"../resources/models/w2v/\").resolve()),\n",
    "        \"w2v_ocr_model\": \"w2v_*_news\",\n",
    "        \"overwrite_dataset\": True,\n",
    "    },\n",
    "    # Parameters to train, load and use a DeezyMatch model:\n",
    "    deezy_parameters={\n",
    "        # Paths and filenames of DeezyMatch models and data:\n",
    "        \"dm_path\": str(Path(\"../resources/deezymatch/\").resolve()), # Path to the DeezyMatch directory where the model is saved.\n",
    "        \"dm_cands\": \"wkdtalts\", # Name we'll give to the folder that will contain the wikidata candidate vectors.\n",
    "        \"dm_model\": \"w2v_ocr\", # Name of the DeezyMatch model.\n",
    "        \"dm_output\": \"deezymatch_on_the_fly\", # Name of the file where the output of DeezyMatch will be stored. Feel free to change that.\n",
    "        # Ranking measures:\n",
    "        \"ranking_metric\": \"faiss\", # Metric used by DeezyMatch to rank the candidates.\n",
    "        \"selection_threshold\": 50, # Threshold for that metric.\n",
    "        \"num_candidates\": 1, # Number of name variations for a string (e.g. \"London\", \"Londra\", and \"Londres\" are three different variations in our gazetteer of \"Londcn\").\n",
    "        \"verbose\": False, # Whether to see the DeezyMatch progress or not.\n",
    "        # DeezyMatch training:\n",
    "        \"overwrite_training\": True, # You can choose to overwrite the model if it exists: in this case we're training a model, regardless of whether it already exists.\n",
    "        \"do_test\": True, # Whether the DeezyMatch model we're loading was a test, or not.\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the resources (i.e. the `mentions-to-wikidata` and `wikidata-to-mentions` mappers) that will be used by the ranker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the resources:\n",
    "myranker.mentions_to_wikidata = myranker.load_resources()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a DeezyMatch model (notice we will be training a `test` model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DeezyMatch model if needed:\n",
    "myranker.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the DeezyMatch model that has been loaded, find candidates on Wikidata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find candidates given a toponym:\n",
    "toponym = \"Manchefter\"\n",
    "print(myranker.find_candidates([{\"mention\": toponym}])[0][toponym])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resolution-cNmUJBkC-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
